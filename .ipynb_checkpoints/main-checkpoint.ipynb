{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import time\n",
    "import numpy as np \n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDevice():\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(f\"Using {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadYoloModel():\n",
    "    model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", pretrained=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSingleImage(imagePath, device, model):\n",
    "    start = time.time()\n",
    "\n",
    "    image = Image.open(imagePath).convert('RGB')\n",
    "    with torch.no_grad():\n",
    "        result = model(image)\n",
    "        result.print()\n",
    "        #print(result.xyxy)\n",
    "        #print(\"Names\")\n",
    "        #print(result.pandas().xyxy[0][\"name\"])\n",
    "        resultNames = result.pandas().xyxy[0][\"name\"]\n",
    "        predictions = result.xyxy[0]\n",
    "\n",
    "        for i in range(len(predictions)):\n",
    "            prediction = predictions[i].tolist()\n",
    "            # print(prediction)\n",
    "            #print(f\"prediction {i}, {resultNames[i]}\")\n",
    "            #print(prediction)\n",
    "            \n",
    "            \n",
    "            if resultNames[i] == \"person\":\n",
    "                indexOfClosest = None\n",
    "                distance = image.size[0]\n",
    "                for j in range(len(predictions)):\n",
    "                    prediction2 = predictions[j].tolist()\n",
    "\n",
    "                    if resultNames[j] == \"person\":\n",
    "                        continue\n",
    "                    else:\n",
    "                        #print(\"prediction for non human object\")\n",
    "                        #print(prediction2)\n",
    "\n",
    "                        # pil image pixel value changing\n",
    "                        temp = np.array(image)\n",
    "\n",
    "                        # debug (draw one pixel green)\n",
    "                        #print(\"coordinates\")\n",
    "                        #print(round(prediction2[0]))\n",
    "                        #print(round(prediction2[1]))\n",
    "                        temp[round(prediction2[1])][round(prediction2[0])]   = [0, 255, 0]\n",
    "                        image = Image.fromarray(temp)\n",
    "                        # debug\n",
    "\n",
    "                        personCenters = (\n",
    "                            (prediction[2] + prediction[0]) // 2, # (xmax + xmin) / 2  -> x but column value\n",
    "                            (prediction[3] + prediction[1]) // 2  # (ymax + ymin) / 2  -> y but row value\n",
    "                        )\n",
    "\n",
    "                        objCenters = (\n",
    "                            (prediction2[2] + prediction2[0]) // 2, # (xmax + xmin) / 2  -> x but column value\n",
    "                            (prediction2[3] + prediction2[1]) // 2  # (ymax + ymin) / 2  -> y but row value\n",
    "                        )\n",
    "                        ImageDraw.Draw(image).line((personCenters[0],personCenters[1], objCenters[0], objCenters[1] ), fill=\"red\", width=3)\n",
    "\n",
    "                        radius = 4\n",
    "                        ImageDraw.Draw(image).ellipse((personCenters[0]-radius,personCenters[1]-radius,personCenters[0]+radius, personCenters[1]+radius), fill=\"red\", outline=\"red\")\n",
    "                        ImageDraw.Draw(image).ellipse((objCenters[0]-radius,objCenters[1]-radius,objCenters[0]+radius, objCenters[1]+radius), fill=\"red\", outline=\"red\")\n",
    "\n",
    "\n",
    "            x_min = round(prediction[0])\n",
    "            y_min = round(prediction[1])\n",
    "            x_max = round(prediction[2])\n",
    "            y_max = round(prediction[3])\n",
    "            cfdnc = prediction[4]\n",
    "            if cfdnc < 0.4 and resultNames[i] != \"person\":\n",
    "                continue\n",
    "            color = None\n",
    "            if resultNames[i] == \"person\":\n",
    "                color = \"blue\"\n",
    "            else:\n",
    "                color = \"green\"  \n",
    "            ImageDraw.Draw(image).rectangle([x_min,y_min,x_max,y_max], outline =color, width=3)\n",
    "    \n",
    "    print(f\"Took {time.time()-start} seconds.\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = setDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained model\n",
    "yoloModel = loadYoloModel()\n",
    "yoloModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImage = detectSingleImage(\"./dataset/train2015/train/HICO_train2015_00000015.jpg\", device, yoloModel)\n",
    "resultImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAnnotationFiles():\n",
    "    trainJSONFile = open('./annotations/train_data_with_obj_id.json')\n",
    "    testJSONFile = open(\"./annotations/test_data_with_obj_id.json\")\n",
    "    verbJSONFile = open('./annotations/verb_dict.json')\n",
    "    verbFile = open('./annotations/hico_list_vb.txt',\"r\")\n",
    "    hoiFile = open('./annotations/hico_list_hoi.txt', \"r\")   \n",
    "    objFile = open('./annotations/hico_list_obj.txt', \"r\")\n",
    "\n",
    "    # reading and configuring txt files\n",
    "    verbFileArray = verbFile.read().split(\"\\n\")\n",
    "    hoiFileArray = hoiFile.read().split(\"\\n\")\n",
    "    objFileArray = objFile.read().split(\"\\n\")\n",
    "    \n",
    "    for i in range(len(objFileArray)):\n",
    "        objFileArray[i] = objFileArray[i].strip(\" \").split(\" \")[-1]\n",
    "    \n",
    "    # loading json files\n",
    "    trainAnnotationDictionary = json.load(trainJSONFile)\n",
    "    verbDictionary = json.load(verbJSONFile)\n",
    "    testAnnotationDictionary = json.load(testJSONFile)\n",
    "\n",
    "    # closing files which has opened\n",
    "    trainJSONFile.close()\n",
    "    verbJSONFile.close()\n",
    "    verbFile.close()\n",
    "    hoiFile.close()\n",
    "    objFile.close()\n",
    "    testJSONFile.close()\n",
    "    \n",
    "    return trainAnnotationDictionary, testAnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray, objFileArray\n",
    "\n",
    "\n",
    "def targetVectorOfAllImages(AnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray):\n",
    "    imageNames = AnnotationDictionary[\"name\"]\n",
    "    actionNumbers = AnnotationDictionary[\"action_no\"]\n",
    "    objectList = AnnotationDictionary[\"obj_list\"]\n",
    "    objectIDs = AnnotationDictionary[\"obj_id\"]\n",
    "    \n",
    "    verbArray = list(verbDictionary.values())\n",
    "\n",
    "    targetVectors = []\n",
    "    for i in imageNames:\n",
    "        actionIndexes = actionNumbers[i]\n",
    "        targetVector = np.zeros(117)\n",
    "\n",
    "        for j in actionIndexes:\n",
    "            # getting relevant verb\n",
    "            tempVerb = hoiFileArray[j - 1].strip(\" \").split(\" \")[-1]\n",
    "\n",
    "            # getting index of verb\n",
    "            tempIndex = verbArray.index(tempVerb)\n",
    "\n",
    "            # setting correct values\n",
    "            targetVector[tempIndex] = 1\n",
    "\n",
    "            print([imageNames[i]], objectList[i], [tempVerb])\n",
    "        \n",
    "        targetVectors.append(targetVector)\n",
    "        \n",
    "    return targetVectors\n",
    " \n",
    "\n",
    "def getIndividualTargetVector(imageName, AnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray, objFileArray):\n",
    "    imageNames = AnnotationDictionary[\"name\"]\n",
    "    actionNumbers = AnnotationDictionary[\"action_no\"]\n",
    "    objectList = AnnotationDictionary[\"obj_list\"]\n",
    "    objectIDs = AnnotationDictionary[\"obj_id\"]\n",
    "    \n",
    "    verbArray = list(verbDictionary.values())\n",
    "    imageNameArray = list(imageNames.values())\n",
    "    \n",
    "    \n",
    "    # extract image index\n",
    "    imageIndex = imageNameArray.index(imageName)\n",
    "    \n",
    "    \n",
    "    # only image names\n",
    "    imageNamesList = list(imageNames.values())\n",
    "    \n",
    "    #initial target vector\n",
    "    targetVector = np.zeros(117)\n",
    "    \n",
    "    # extract action indexes \n",
    "    actionIndexes = list(actionNumbers.values())[imageIndex]\n",
    "    \n",
    "    \n",
    "    # convert object list \n",
    "    objectList = list(objectList.values())\n",
    "    for i in actionIndexes:\n",
    "        verb = hoiFileArray[i - 1].strip(\" \").split(\" \")[-1]\n",
    "        \n",
    "        tempIndex = verbArray.index(verb)\n",
    "        \n",
    "        targetVector[tempIndex] = 1\n",
    "        \n",
    "        #obj = objectList[imageIndex - 1].split(\" \")[-1]\n",
    "        objIndex = objFileArray.index(objectList[imageIndex - 1][0])\n",
    "        \n",
    "        #print([imageNamesList[imageIndex - 1]], objectList[imageIndex - 1], [verb])\n",
    "        #print(imageIndex - 1)\n",
    "        #print(objIndex)\n",
    "    \n",
    "    return [objIndex, targetVector]   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"read needed files and configure\"\"\"\n",
    "trainAnnotationDictionary, testAnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray, objFileArray = readAnnotationFiles()\n",
    "\n",
    "\"\"\"create target vector for all the images\"\"\"\n",
    "# targetVectorOfAllImages(trainAnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray\n",
    "\n",
    "\"\"\"return target vector of given image\"\"\"\n",
    "\n",
    "targetVector = getIndividualTargetVector(\"HICO_train2015_00000016.jpg\",trainAnnotationDictionary,verbDictionary, verbFileArray, hoiFileArray, objFileArray)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "print(targetVector)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "dataset_path = './dataset/train2015'\n",
    "\n",
    "mean = torch.tensor([0.485, 0.456, 0.406], dtype=torch.float32)\n",
    "std = torch.tensor([0.229, 0.224, 0.225], dtype=torch.float32)\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "    transforms.Resize(300),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    "\n",
    "myDataset = []\n",
    "\n",
    "\n",
    "for i in range(len(dataset.imgs)):\n",
    "    \n",
    "    tempImageName = dataset.imgs[i][0].split(\"\\\\\")[-1]\n",
    "    targetVector = getIndividualTargetVector(tempImageName,trainAnnotationDictionary,verbDictionary, verbFileArray, hoiFileArray, objFileArray)\n",
    "    dataset.imgs[i] = (dataset.imgs[i][0], targetVector)\n",
    "    \"\"\"\n",
    "    if (i % 1000 == 999):\n",
    "        break # burayı boz\n",
    "    \"\"\"\n",
    "dataset.classes = list(verbDictionary.values())\n",
    "\n",
    "print(\"hawli\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F1\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(512, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(512, 117)\n",
    "\n",
    "        self.linear3 = nn.Linear(512,80)   \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F1.softmax(self.linear1(x))\n",
    "        out = F1.softmax(self.linear1(out))\n",
    "        out = self.linear2(x+residual)\n",
    "\n",
    "        out2 = self.linear3(x)\n",
    "\n",
    "        return out, out2\n",
    "\n",
    "\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Sequential()\n",
    "myModel = MyModel().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(myModel.parameters(),lr= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epoch = 50\n",
    "\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(myModel.parameters(),lr= 0.001)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=dataset, batch_size = 16, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    loss = 0\n",
    "    \n",
    "    for j, batch in enumerate(train_dataloader, 1):\n",
    "        \n",
    "        \n",
    "        minput = batch[0]\n",
    "        target = batch[1]\n",
    "        \n",
    "        moutput = model(minput.to(device))\n",
    "        moutput = myModel(moutput.to(device))\n",
    "        \n",
    "        \n",
    "        #loss2 = criterion2(moutput[0], target[1]).to(torch.float32)\n",
    "        loss2 = F1.mse_loss(moutput[0].float(), target[1].float()).to(torch.float32)\n",
    "        \n",
    "        #loss1 = criterion1(moutput[1], target[0]).to(torch.float32)\n",
    "        loss1 = F1.cross_entropy(moutput[1].float(), target[0]).to(torch.float32)\n",
    "        \n",
    "        \"\"\"loss2 = criterion1(moutput[1], target[0])\n",
    "\n",
    "        loss1 = criterion2(moutput[0], target[1][0])\"\"\"\n",
    "        \n",
    "        loss = loss1 + loss2\n",
    "        \n",
    "        print(\"loss\", loss.item(), j)\n",
    "        \n",
    "        \"\"\" \n",
    "        print(\"predict_class, real_class\", list(moutput[1][0]).index(max(moutput[1][0])), target[0][0])\n",
    "        print(\" \")\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    print(\"Epoch Finished\", i)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
