{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import time\n",
    "import numpy as np \n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDevice():\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(f\"Using {device}\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadYoloModel():\n",
    "    model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5x6\", pretrained=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectSingleImage(imagePath, device, model, isPath, image):\n",
    "    if isPath:\n",
    "        image = Image.open(imagePath).convert('RGB')\n",
    "    else:\n",
    "        image = image\n",
    "    start = time.time()\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        result = model(image)\n",
    "        result.print()\n",
    "        #print(result.xyxy)\n",
    "        #print(\"Names\")\n",
    "        #print(result.pandas().xyxy[0][\"name\"])\n",
    "        resultNames = result.pandas().xyxy[0][\"name\"]\n",
    "        predictions = result.xyxy[0]\n",
    "\n",
    "        for i in range(len(predictions)):\n",
    "            prediction = predictions[i].tolist()\n",
    "            # print(prediction)\n",
    "            #print(f\"prediction {i}, {resultNames[i]}\")\n",
    "            #print(prediction)\n",
    "            \n",
    "            \n",
    "            if resultNames[i] == \"person\":\n",
    "                indexOfClosest = None\n",
    "                distance = image.size[0]\n",
    "                for j in range(len(predictions)):\n",
    "                    prediction2 = predictions[j].tolist()\n",
    "\n",
    "                    if resultNames[j] == \"person\":\n",
    "                        continue\n",
    "                    else:\n",
    "                        #print(\"prediction for non human object\")\n",
    "                        #print(prediction2)\n",
    "\n",
    "                        # pil image pixel value changing\n",
    "                        temp = np.array(image)\n",
    "\n",
    "                        # debug (draw one pixel green)\n",
    "                        #print(\"coordinates\")\n",
    "                        #print(round(prediction2[0]))\n",
    "                        #print(round(prediction2[1]))\n",
    "                        temp[round(prediction2[1])][round(prediction2[0])]   = [0, 255, 0]\n",
    "                        image = Image.fromarray(temp)\n",
    "                        # debug\n",
    "\n",
    "                        personCenters = (\n",
    "                            (prediction[2] + prediction[0]) // 2, # (xmax + xmin) / 2  -> x but column value\n",
    "                            (prediction[3] + prediction[1]) // 2  # (ymax + ymin) / 2  -> y but row value\n",
    "                        )\n",
    "\n",
    "                        objCenters = (\n",
    "                            (prediction2[2] + prediction2[0]) // 2, # (xmax + xmin) / 2  -> x but column value\n",
    "                            (prediction2[3] + prediction2[1]) // 2  # (ymax + ymin) / 2  -> y but row value\n",
    "                        )\n",
    "                        ImageDraw.Draw(image).line((personCenters[0],personCenters[1], objCenters[0], objCenters[1] ), fill=\"red\", width=3)\n",
    "\n",
    "                        radius = 4\n",
    "                        ImageDraw.Draw(image).ellipse((personCenters[0]-radius,personCenters[1]-radius,personCenters[0]+radius, personCenters[1]+radius), fill=\"red\", outline=\"red\")\n",
    "                        ImageDraw.Draw(image).ellipse((objCenters[0]-radius,objCenters[1]-radius,objCenters[0]+radius, objCenters[1]+radius), fill=\"red\", outline=\"red\")\n",
    "\n",
    "\n",
    "            x_min = round(prediction[0])\n",
    "            y_min = round(prediction[1])\n",
    "            x_max = round(prediction[2])\n",
    "            y_max = round(prediction[3])\n",
    "            cfdnc = prediction[4]\n",
    "            if cfdnc < 0.4 and resultNames[i] != \"person\":\n",
    "                continue\n",
    "            color = None\n",
    "            if resultNames[i] == \"person\":\n",
    "                color = \"blue\"\n",
    "            else:\n",
    "                color = \"green\"  \n",
    "            ImageDraw.Draw(image).rectangle([x_min,y_min,x_max,y_max], outline =color, width=3)\n",
    "    \n",
    "    print(f\"Took {time.time()-start} seconds.\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = setDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained model\n",
    "yoloModel = loadYoloModel()\n",
    "yoloModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectHighestScoreImage(imagePath, device, model, isPath, image):\n",
    "    if isPath:\n",
    "        image = Image.open(imagePath).convert('RGB')\n",
    "    else:\n",
    "        image = image\n",
    "    start = time.time()\n",
    "        \n",
    "\n",
    "    with torch.no_grad():\n",
    "        result = model(image)\n",
    "        # result.print()\n",
    "        resultNames = result.pandas().xyxy[0][\"name\"]\n",
    "        # max values\n",
    "        personMax = 0\n",
    "        personIndex = None\n",
    "        objectMax = 0\n",
    "        objectIndex = None\n",
    "        for i, prediction in enumerate(result.xyxy[0],0):\n",
    "            if resultNames[i] == \"person\":\n",
    "                if prediction[4] > personMax:\n",
    "                    personMax = prediction[4]\n",
    "                    personIndex = i\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                if prediction[4] > objectMax:\n",
    "                    objectMax = prediction[4]\n",
    "                    objectIndex = i\n",
    "            \n",
    "        if objectIndex is None:\n",
    "            if personIndex is not None:\n",
    "                objectIndex = personIndex\n",
    "        elif personIndex is None:\n",
    "            if objectIndex is not None:\n",
    "                personIndex = objectIndex\n",
    "        elif (personIndex is None) and (objectIndex is None):\n",
    "            return [image, image, image]\n",
    "        \n",
    "        # print(f\"{resultNames[i]}, {prediction}, {prediction[4]}\")\n",
    "        # print(personIndex, personIndex is not None,  personIndex is None)\n",
    "        # print(objectIndex, objectIndex is not None,  objectIndex is None)\n",
    "        # print(f\"object: {objectMax}, {resultNames[objectIndex]},{result.xyxy[0][objectIndex]}\")\n",
    "        # print(f\"person: {personMax}, {resultNames[personIndex]},{result.xyxy[0][personIndex]}\")\n",
    "        \n",
    "        \n",
    "        objCoordinates = result.xyxy[0][objectIndex][:4]\n",
    "        personCoordinates = result.xyxy[0][personIndex][:4]\n",
    "        objCoordinates = objCoordinates.cpu().detach().numpy().astype(int)\n",
    "        personCoordinates = personCoordinates.cpu().detach().numpy().astype(int)\n",
    "\n",
    "        humanImage = image.crop(list(personCoordinates))\n",
    "        objectImage = image.crop(list(objCoordinates))\n",
    "\n",
    "\n",
    "\n",
    "        # drawing rectangles and linking lines for pair stream\n",
    "        ImageDraw.Draw(image).rectangle(list(objCoordinates),width=3, outline=\"green\")\n",
    "        ImageDraw.Draw(image).rectangle(list(personCoordinates),width=3, outline=\"blue\")\n",
    "\n",
    "        #linking\n",
    "        objCenters = (\n",
    "            (objCoordinates[2] + objCoordinates[0]) // 2, # (xmax + xmin) / 2  -> x but column value\n",
    "            (objCoordinates[3] + objCoordinates[1]) // 2  # (ymax + ymin) / 2  -> y but row value\n",
    "        )\n",
    "\n",
    "        personCenters = (\n",
    "            (personCoordinates[2] + personCoordinates[0]) // 2, # (xmax + xmin) / 2  -> x but column value\n",
    "            (personCoordinates[3] + personCoordinates[1]) // 2  # (ymax + ymin) / 2  -> y but row value\n",
    "        )\n",
    "        ImageDraw.Draw(image).line((personCenters[0],personCenters[1], objCenters[0], objCenters[1] ), fill=\"red\", width=3)\n",
    "        radius = 4\n",
    "        ImageDraw.Draw(image).ellipse((personCenters[0]-radius,personCenters[1]-radius,personCenters[0]+radius, personCenters[1]+radius), fill=\"red\", outline=\"red\")\n",
    "        ImageDraw.Draw(image).ellipse((objCenters[0]-radius,objCenters[1]-radius,objCenters[0]+radius, objCenters[1]+radius), fill=\"red\", outline=\"red\")\n",
    "\n",
    "\n",
    "        pairWise_x_min = min([objCoordinates[0], personCoordinates[0]])\n",
    "        pairWise_y_min = min([objCoordinates[1], personCoordinates[1]])\n",
    "        pairWise_x_max = max([objCoordinates[2], personCoordinates[2]])\n",
    "        pairWise_y_max = max([objCoordinates[3], personCoordinates[3]])\n",
    "        pairWiseStream = image.crop([pairWise_x_min,pairWise_y_min ,pairWise_x_max ,pairWise_y_max ])\n",
    "\n",
    "        \n",
    "        return [humanImage, objectImage, pairWiseStream]\n",
    "        \n",
    "        \n",
    "tempImage = selectHighestScoreImage(\"./dataset/train2015/train/HICO_train2015_00000265.jpg\", device, yoloModel, True, None)\n",
    "tempImage[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultImage = detectSingleImage(\"./dataset/train2015/train/HICO_train2015_00000010.jpg\", device, yoloModel, True, None)\n",
    "resultImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readAnnotationFiles():\n",
    "    trainJSONFile = open('./annotations/train_data_with_obj_id.json')\n",
    "    testJSONFile = open(\"./annotations/test_data_with_obj_id.json\")\n",
    "    verbJSONFile = open('./annotations/verb_dict.json')\n",
    "    verbFile = open('./annotations/hico_list_vb.txt',\"r\")\n",
    "    hoiFile = open('./annotations/hico_list_hoi.txt', \"r\")   \n",
    "    objFile = open('./annotations/hico_list_obj.txt', \"r\")\n",
    "    \n",
    "\n",
    "    # reading and configuring txt files\n",
    "    verbFileArray = verbFile.read().split(\"\\n\")\n",
    "    hoiFileArray = hoiFile.read().split(\"\\n\")\n",
    "    objFileArray = objFile.read().split(\"\\n\")\n",
    "    \n",
    "    for i in range(len(objFileArray)):\n",
    "        objFileArray[i] = objFileArray[i].strip(\" \").split(\" \")[-1]\n",
    "    \n",
    "    # loading json files\n",
    "    trainAnnotationDictionary = json.load(trainJSONFile)\n",
    "    verbDictionary = json.load(verbJSONFile)\n",
    "    testAnnotationDictionary = json.load(testJSONFile)\n",
    "\n",
    "    # closing files which has opened\n",
    "    trainJSONFile.close()\n",
    "    verbJSONFile.close()\n",
    "    verbFile.close()\n",
    "    hoiFile.close()\n",
    "    objFile.close()\n",
    "    testJSONFile.close()\n",
    "    \n",
    "    return trainAnnotationDictionary, testAnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray, objFileArray\n",
    "\n",
    "\n",
    "def targetVectorOfAllImages(AnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray):\n",
    "    imageNames = AnnotationDictionary[\"name\"]\n",
    "    actionNumbers = AnnotationDictionary[\"action_no\"]\n",
    "    objectList = AnnotationDictionary[\"obj_list\"]\n",
    "    objectIDs = AnnotationDictionary[\"obj_id\"]\n",
    "    \n",
    "    verbArray = list(verbDictionary.values())\n",
    "\n",
    "    targetVectors = []\n",
    "    for i in imageNames:\n",
    "        actionIndexes = actionNumbers[i]\n",
    "        targetVector = np.zeros(117)\n",
    "\n",
    "        for j in actionIndexes:\n",
    "            # getting relevant verb\n",
    "            tempVerb = hoiFileArray[j - 1].strip(\" \").split(\" \")[-1]\n",
    "\n",
    "            # getting index of verb\n",
    "            tempIndex = verbArray.index(tempVerb)\n",
    "\n",
    "            # setting correct values\n",
    "            targetVector[tempIndex] = 1\n",
    "\n",
    "            print([imageNames[i]], objectList[i], [tempVerb])\n",
    "        \n",
    "        targetVectors.append(targetVector)\n",
    "        \n",
    "    return targetVectors\n",
    " \n",
    "def getIndividualTargetVector(imageName, AnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray, objFileArray):\n",
    "    imageNames = AnnotationDictionary[\"name\"]\n",
    "    actionNumbers = AnnotationDictionary[\"action_no\"]\n",
    "    objectList = AnnotationDictionary[\"obj_list\"]\n",
    "    objectIDs = AnnotationDictionary[\"obj_id\"]\n",
    "\n",
    "    verbArray = list(verbDictionary.values())\n",
    "    imageNameArray = list(imageNames.values())\n",
    "\n",
    "    # extract image index\n",
    "    imageIndex = imageNameArray.index(imageName)\n",
    "\n",
    "    # only image names\n",
    "    imageNamesList = list(imageNames.values())\n",
    "\n",
    "    #initial target vector\n",
    "    targetVector = np.zeros(600)\n",
    "\n",
    "    # extract action indexes \n",
    "    actionIndexes = list(actionNumbers.values())[imageIndex]\n",
    "\n",
    "    # convert object list \n",
    "    objectList = list(objectList.values())\n",
    "    for i in actionIndexes:\n",
    "        targetVector[i-1] = 1\n",
    "        \n",
    "    return targetVector\n",
    "    \n",
    "    \n",
    "def getIndividualTargetVector_old(imageName, AnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray, objFileArray):\n",
    "    imageNames = AnnotationDictionary[\"name\"]\n",
    "    actionNumbers = AnnotationDictionary[\"action_no\"]\n",
    "    objectList = AnnotationDictionary[\"obj_list\"]\n",
    "    objectIDs = AnnotationDictionary[\"obj_id\"]\n",
    "    \n",
    "    verbArray = list(verbDictionary.values())\n",
    "    imageNameArray = list(imageNames.values())\n",
    "    \n",
    "    \n",
    "    # extract image index\n",
    "    imageIndex = imageNameArray.index(imageName)\n",
    "    \n",
    "    \n",
    "    # only image names\n",
    "    imageNamesList = list(imageNames.values())\n",
    "    \n",
    "    #initial target vector\n",
    "    targetVector = np.zeros(117)\n",
    "    \n",
    "    # extract action indexes \n",
    "    actionIndexes = list(actionNumbers.values())[imageIndex]\n",
    "    \n",
    "    \n",
    "    # convert object list \n",
    "    objectList = list(objectList.values())\n",
    "    for i in actionIndexes:\n",
    "        verb = hoiFileArray[i - 1].strip(\" \").split(\" \")[-1]\n",
    "        \n",
    "        tempIndex = verbArray.index(verb)\n",
    "        \n",
    "        targetVector[tempIndex] = 1\n",
    "        \n",
    "        #obj = objectList[imageIndex - 1].split(\" \")[-1]\n",
    "        objIndex = objFileArray.index(objectList[imageIndex - 1][0])\n",
    "        \n",
    "        #print([imageNamesList[imageIndex - 1]], objectList[imageIndex - 1], [verb])\n",
    "        #print(imageIndex - 1)\n",
    "        #print(objIndex)\n",
    "    \n",
    "    return [objIndex, targetVector]   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"read needed files and configure\"\"\"\n",
    "trainAnnotationDictionary, testAnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray, objFileArray = readAnnotationFiles()\n",
    "\n",
    "\"\"\"create target vector for all the images\"\"\"\n",
    "# targetVectorOfAllImages(trainAnnotationDictionary, verbDictionary, verbFileArray, hoiFileArray\n",
    "\n",
    "\"\"\"return target vector of given image\"\"\"\n",
    "\n",
    "targetVector = getIndividualTargetVector(\"HICO_train2015_00000020.jpg\",trainAnnotationDictionary,verbDictionary, verbFileArray, hoiFileArray, objFileArray)\n",
    "\n",
    "print(targetVector)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransform(object):\n",
    "    def __call__(self,image):\n",
    "        drawedImage = selectHighestScoreImage(None, device, yoloModel, False, image)\n",
    "            # function call\n",
    "        return drawedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def loadDataset(dataset_path, hoiFileArray):\n",
    "\n",
    "    # transform = transforms.Compose([\n",
    "    #     CustomTransform() # \n",
    "    # ])\n",
    "\n",
    "    # , transform=transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    dataset = torchvision.datasets.ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    #target vector replacement\n",
    "    for i in range(len(dataset.imgs)):\n",
    "\n",
    "        tempImageName = dataset.imgs[i][0].split(\"\\\\\")[-1]\n",
    "        targetVector = getIndividualTargetVector(tempImageName,trainAnnotationDictionary,verbDictionary, verbFileArray, hoiFileArray, objFileArray)\n",
    "        # print(len(targetVector))\n",
    "        dataset.imgs[i] = (dataset.imgs[i][0], targetVector)\n",
    "        if (i % 1000 == 0):\n",
    "            print(i)\n",
    "            \n",
    "    # changing classes\n",
    "    try:\n",
    "        for i,value in enumerate(hoiFileArray,0):\n",
    "            tempArray = value.strip(\" \").split(\" \")[2:]\n",
    "            text = tempArray[0]+\" \"+tempArray[-1]\n",
    "            hoiFileArray[i] = text\n",
    "    except IndexError:\n",
    "        pass\n",
    "\n",
    "    # update dataset classes\n",
    "    dataset.classes = hoiFileArray\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = loadDataset('./dataset/train2015', hoiFileArray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(512, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(1024, 512)\n",
    "        self.linear3 = nn.Linear(512,600)   \n",
    "\n",
    "        # self.linear1 = nn.Linear(1536, 1024)\n",
    "        # self.reu = nn.ReLU()\n",
    "        # self.linear2 = nn.Linear(1024, 1024)\n",
    "        # self.linear3 = nn.Linear(1024,600)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.linear1(x))\n",
    "        out = self.relu(self.linear2(out))\n",
    "        out = self.linear3(out+residual)\n",
    "        return out\n",
    "\n",
    "# resnext50_32x4d \n",
    "\n",
    "\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "model.fc = nn.Sequential()\n",
    "myModel = MyModel().to(device)\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.Adam(myModel.parameters(),lr= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, end):\n",
    "    torch.save(model,f\"./models/model_{end}.pth\")\n",
    "    print(\"Model saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(path, device):\n",
    "    return torch.load(path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch, savePerIteration):\n",
    "    print(\"Learning...\")\n",
    "\n",
    "    lossValues = []\n",
    "    #BCEWithLogitsLoss idi\n",
    "    criterion = nn.BCELoss()\n",
    "    criterion2 = nn.Sigmoid()\n",
    "    optimizer = optim.Adam(myModel.parameters(),lr= 0.001)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=dataset, batch_size = 1, shuffle = True)\n",
    "\n",
    "\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], dtype=torch.float32)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225], dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    for i in range(epoch):\n",
    "        counter = 1\n",
    "        totalLoss = 0\n",
    "\n",
    "        for j, batch in enumerate(train_dataloader, 27):\n",
    "            # if j%27 != 0:\n",
    "            #     continue\n",
    "\n",
    "            minput = batch[0]\n",
    "            target = batch[1]\n",
    "            # print(target)\n",
    "            # print(minput.shape)\n",
    "            \n",
    "            tempImage = transforms.ToPILImage()(minput[0]).convert('RGB')\n",
    "            # print(tempImage)\n",
    "            # print(target)\n",
    "            \n",
    "            imageArray = selectHighestScoreImage(None, device, yoloModel, False, tempImage)\n",
    "            # print(imageArray)\n",
    "            humanImage = imageArray[0]\n",
    "            objectImage = imageArray[1]\n",
    "            pairWiseStream = imageArray[2]\n",
    "            \n",
    "            #transforms\n",
    "            tempTransforms  = transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=mean, std=std)\n",
    "            ])\n",
    "            humanImage = tempTransforms(humanImage).unsqueeze(1).permute(1,0,2,3)\n",
    "            objectImage = tempTransforms(objectImage).unsqueeze(1).permute(1,0,2,3)\n",
    "            pairWiseStream = tempTransforms(pairWiseStream).unsqueeze(1).permute(1,0,2,3)\n",
    "            # print(humanImage.shape)\n",
    "            \n",
    "            # resnet model\n",
    "            humanOutput = model(humanImage.to(device))\n",
    "            objectOutput = model(objectImage.to(device))\n",
    "            pairWiseStreamOutput = model(pairWiseStream.to(device))\n",
    "            #deneme\n",
    "            # testInput = torch.cat((humanOutput, objectOutput, pairWiseStreamOutput), 1)\n",
    "            # print(humanOutput.shape)\n",
    "            #deneme\n",
    "        \n",
    "            # our model output\n",
    "            humanOutput = myModel(humanOutput.to(device))\n",
    "            objectOutput = myModel(objectOutput.to(device))\n",
    "            pairWiseStreamOutput = myModel(pairWiseStreamOutput.to(device))\n",
    "            \n",
    "            \n",
    "            elementWiseSum = (humanOutput + objectOutput + pairWiseStreamOutput)/3\n",
    "            \n",
    "            # print(elementWiseSum)\n",
    "            \n",
    "            \n",
    "            # print(elementWiseSum.shape, elementWiseSum)\n",
    "            # print(target.shape, target)\n",
    "            # print(humanOutput.shape)\n",
    "            # print(humanOutput)\n",
    "            # our model\n",
    "            # print(target)\n",
    "            \n",
    "            # print(elementWiseSum.shape)\n",
    "            # print(target.shape)\n",
    "            \n",
    "            #deneme\n",
    "            #print(testInput.shape)\n",
    "            #testOutput = myModel(testInput)\n",
    "            \n",
    "            # loss = criterion(testInput, target.to(device))\n",
    "            loss = criterion(criterion2(elementWiseSum).float(), target.float().to(device))\n",
    "            # loss = criterion(elementWiseSum, target.to(device))\n",
    "            \n",
    "            # printing loss value\n",
    "            # print(\"loss: \",loss)\n",
    "            # print(elementWiseSum.shape)\n",
    "            \n",
    "            if counter % savePerIteration == 0:\n",
    "                predictionArray = list(elementWiseSum[0])\n",
    "                predictionArray = sorted(predictionArray,reverse=True)\n",
    "                for l in range(5):\n",
    "                    print(list(elementWiseSum[0]).index(predictionArray[l]))\n",
    "\n",
    "                print(\"Reals\")\n",
    "                for m,value in enumerate(list(target[0]),0):\n",
    "                    if value > 0.8:\n",
    "                        print(m)\n",
    "                    \n",
    "            if counter % savePerIteration == 0:\n",
    "                print(f\"Avg loss: {totalLoss/counter}\")\n",
    "                saveModel(myModel, f\"avgloss_{totalLoss/counter}\")\n",
    "            \n",
    "            #\n",
    "            totalLoss += loss.item()\n",
    "            lossValues.append(loss.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            counter += 1\n",
    "            # break\n",
    "#             break\n",
    "\n",
    "#             moutput = model(minput.to(device))\n",
    "#             moutput = myModel(moutput.to(device))\n",
    "\n",
    "#             # losslarÄ± ayarla\n",
    "#             #loss2 = criterion2(moutput[0], target[1]).to(torch.float32)\n",
    "#             loss2 = F.mse_loss(moutput[0].float(), target[1].float()).to(torch.float32)\n",
    "\n",
    "#             #loss1 = criterion1(moutput[1], target[0]).to(torch.float32)\n",
    "#             loss1 = F.cross_entropy(moutput[1].float(), target[0]).to(torch.float32)\n",
    "\n",
    "#             \"\"\"loss2 = criterion1(moutput[1], target[0])\n",
    "\n",
    "#             loss1 = criterion2(moutput[0], target[1][0])\"\"\"\n",
    "\n",
    "#             loss = loss1 + loss2\n",
    "\n",
    "#             print(\"loss\", loss.item(), j)\n",
    "\n",
    "#             \"\"\" \n",
    "#             print(\"predict_class, real_class\", list(moutput[1][0]).index(max(moutput[1][0])), target[0][0])\n",
    "#             print(\" \")\n",
    "\n",
    "#             \"\"\"\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "# \n",
    "        print(\"Epoch Finished\", i)\n",
    "        \n",
    "        \n",
    "train(100, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
